{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f6ad44-44c2-4a00-b587-25b6d1b629e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Installation Report ####\n",
      "\n",
      "------------ Environment ------------\n",
      "Colossal-AI version: 0.3.6\n",
      "PyTorch version: 1.12.1\n",
      "System CUDA version: 11.3\n",
      "CUDA version required by PyTorch: 11.3\n",
      "\n",
      "Note:\n",
      "1. The table above checks the versions of the libraries/tools in the current environment\n",
      "2. If the System CUDA version is N/A, you can set the CUDA_HOME environment variable to locate it\n",
      "3. If the CUDA version required by PyTorch is N/A, you probably did not install a CUDA-compatible PyTorch. This value is give by torch.version.cuda and you can go to https://pytorch.org/get-started/locally/ to download the correct version.\n",
      "\n",
      "------------ CUDA Extensions AOT Compilation ------------\n",
      "Found AOT CUDA Extension: ✓\n",
      "PyTorch version used for AOT compilation: N/A\n",
      "CUDA version used for AOT compilation: N/A\n",
      "\n",
      "Note:\n",
      "1. AOT (ahead-of-time) compilation of the CUDA kernels occurs during installation when the environment variable BUILD_EXT=1 is set\n",
      "2. If AOT compilation is not enabled, stay calm as the CUDA kernels can still be built during runtime\n",
      "\n",
      "------------ Compatibility ------------\n",
      "PyTorch version match: N/A\n",
      "System and PyTorch CUDA version match: ✓\n",
      "System and Colossal-AI CUDA version match: N/A\n",
      "\n",
      "Note:\n",
      "1. The table above checks the version compatibility of the libraries/tools in the current environment\n",
      "   - PyTorch version mismatch: whether the PyTorch version in the current environment is compatible with the PyTorch version used for AOT compilation\n",
      "   - System and PyTorch CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version required by PyTorch\n",
      "   - System and Colossal-AI CUDA version match: whether the CUDA version in the current environment is compatible with the CUDA version used for AOT compilation\n"
     ]
    }
   ],
   "source": [
    "!colossalai check -i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28630a3d-74f3-4865-9bc0-bb6dd685cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: export: `=/usr/bin/supervisord': not a valid identifier\n",
      "Error: failed to run torchrun --nproc_per_node=1 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=29500 train_resnet.py -c ./ckpt-torch_ddp32 on 127.0.0.1, is localhost: True, exception: Encountered a bad command exit code!\n",
      "\n",
      "Command: 'cd /root && export    =\"/usr/bin/supervisord\" SHELL=\"/bin/bash\" NV_LIBCUBLAS_VERSION=\"11.4.2.10064-1\" NVIDIA_VISIBLE_DEVICES=\"GPU-be02ccaf-d7d3-2a8f-e26e-c44ec54e265e\" NV_NVML_DEV_VERSION=\"11.3.58-1\" NV_CUDNN_PACKAGE_NAME=\"libcudnn8\" NV_LIBNCCL_DEV_PACKAGE=\"libnccl-dev=2.9.6-1+cuda11.3\" NV_LIBNCCL_DEV_PACKAGE_VERSION=\"2.9.6-1\" HOSTNAME=\"autodl-container-78d4478e04-87372e7f\" LANGUAGE=\"zh_CN.UTF-8\" NVIDIA_REQUIRE_CUDA=\"cuda>=11.3 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 driver>=450\" NV_LIBCUBLAS_DEV_PACKAGE=\"libcublas-dev-11-3=11.4.2.10064-1\" NV_NVTX_VERSION=\"11.3.58-1\" NV_ML_REPO_ENABLED=\"1\" NV_CUDA_CUDART_DEV_VERSION=\"11.3.58-1\" NV_LIBCUSPARSE_VERSION=\"11.5.0.58-1\" NV_LIBNPP_VERSION=\"11.3.3.44-1\" NCCL_VERSION=\"2.9.6-1\" PWD=\"/root\" AutoDLContainerUUID=\"78d4478e04-87372e7f\" NV_CUDNN_PACKAGE=\"libcudnn8=8.2.0.53-1+cuda11.3\" NVIDIA_DRIVER_CAPABILITIES=\"compute,utility,graphics,video\" NV_LIBNPP_PACKAGE=\"libnpp-11-3=11.3.3.44-1\" NV_LIBNCCL_DEV_PACKAGE_NAME=\"libnccl-dev\" _=\"/root/miniconda3/bin/colossalai\" TZ=\"Asia/Shanghai\" NV_LIBCUBLAS_DEV_VERSION=\"11.4.2.10064-1\" NV_LIBCUBLAS_DEV_PACKAGE_NAME=\"libcublas-dev-11-3\" NV_CUDA_CUDART_VERSION=\"11.3.58-1\" AutoDLServiceURL=\"https://u257456-8e04-87372e7f.westb.seetacloud.com:8443\" HOME=\"/root\" LANG=\"zh_CN.UTF-8\" AutoDLRegion=\"west-B\" CUDA_VERSION=\"11.3.0\" AgentHost=\"172.20.0.144\" NV_LIBCUBLAS_PACKAGE=\"libcublas-11-3=11.4.2.10064-1\" PYDEVD_USE_FRAME_EVAL=\"NO\" CLICOLOR=\"1\" NV_LIBNPP_DEV_PACKAGE=\"libnpp-dev-11-3=11.3.3.44-1\" NV_LIBCUBLAS_PACKAGE_NAME=\"libcublas-11-3\" NV_LIBNPP_DEV_VERSION=\"11.3.3.44-1\" JPY_PARENT_PID=\"717\" TERM=\"xterm-color\" NV_ML_REPO_URL=\"https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64\" NV_LIBCUSPARSE_DEV_VERSION=\"11.5.0.58-1\" GIT_PAGER=\"cat\" LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\" NV_CUDNN_VERSION=\"8.2.0.53\" AutodlAutoPanelToken=\"jupyter-autodl-container-547b4d909a-075307ba-90190907165c549f8948829b60b7dc34c06130d44baab41ad8d753642ef506d8d\" SHLVL=\"1\" PAGER=\"cat\" NV_CUDA_LIB_VERSION=\"11.3.0-1\" NVARCH=\"x86_64\" NV_CUDNN_PACKAGE_DEV=\"libcudnn8-dev=8.2.0.53-1+cuda11.3\" NV_CUDA_COMPAT_PACKAGE=\"cuda-compat-11-3\" MPLBACKEND=\"module://matplotlib_inline.backend_inline\" NV_LIBNCCL_PACKAGE=\"libnccl2=2.9.6-1+cuda11.3\" LD_LIBRARY_PATH=\"/usr/local/nvidia/lib:/usr/local/nvidia/lib64\" LC_CTYPE=\"C.UTF-8\" REQUESTS_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\" OMP_NUM_THREADS=\"12\" PATH=\"/root/miniconda3/bin:/usr/local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" NV_LIBNCCL_PACKAGE_NAME=\"libnccl2\" NV_LIBNCCL_PACKAGE_VERSION=\"2.9.6-1\" MKL_NUM_THREADS=\"12\" DEBIAN_FRONTEND=\"noninteractive\" && torchrun --nproc_per_node=1 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=29500 train_resnet.py -c ./ckpt-torch_ddp32'\n",
      "\n",
      "Exit code: 1\n",
      "\n",
      "Stdout: already printed\n",
      "\n",
      "Stderr: already printed\n",
      "\n",
      "\n",
      "\n",
      "====== Training on All Nodes =====\n",
      "127.0.0.1: failure\n",
      "\n",
      "====== Stopping All Nodes =====\n",
      "127.0.0.1: finish\n"
     ]
    }
   ],
   "source": [
    "!colossalai run --nproc_per_node 1 train_resnet.py -c ./ckpt-torch_ddp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b42b984-6185-490d-8b6a-a2f036ffe132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
      "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
      "/root/miniconda3/lib/python3.8/site-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
      "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
      "\u001b[2;36m[04/11/24 13:57:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO:                    \n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/miniconda3/lib/python3.8/site-packages/coloss\u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35malai/\u001b[0m\u001b[95minitialize.py\u001b[0m:\u001b[1;36m67\u001b[0m launch                       \n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO: Distributed        \n",
      "\u001b[2;36m                    \u001b[0m         environment is initialized, world size: \u001b[1;36m1\u001b[0m          \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
      "[extension] Time taken to compile cpu_adam_x86 op: 0.5586597919464111 seconds\n",
      "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
      "[extension] Time taken to compile fused_optim_cuda op: 0.6581718921661377 seconds\n",
      "Epoch [1/80]: 100%|████████████████| 500/500 [00:29<00:00, 17.24it/s, loss=1.41]\n",
      "Epoch [2/80]: 100%|████████████████| 500/500 [00:28<00:00, 17.36it/s, loss=1.14]\n",
      "Epoch [3/80]: 100%|███████████████| 500/500 [00:28<00:00, 17.76it/s, loss=0.971]\n",
      "Epoch [4/80]: 100%|███████████████| 500/500 [00:28<00:00, 17.55it/s, loss=0.939]\n",
      "Epoch [5/80]: 100%|███████████████| 500/500 [00:28<00:00, 17.82it/s, loss=0.839]\n",
      "Epoch [6/80]: 100%|███████████████| 500/500 [00:26<00:00, 19.19it/s, loss=0.816]\n",
      "Epoch [7/80]: 100%|███████████████| 500/500 [00:26<00:00, 18.79it/s, loss=0.841]\n",
      "Epoch [8/80]: 100%|███████████████| 500/500 [00:27<00:00, 18.14it/s, loss=0.685]\n",
      "Epoch [9/80]: 100%|███████████████| 500/500 [00:27<00:00, 18.34it/s, loss=0.721]\n",
      "Epoch [10/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.64it/s, loss=0.688]\n",
      "Epoch [11/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.67it/s, loss=0.764]\n",
      "Epoch [12/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.78it/s, loss=0.737]\n",
      "Epoch [13/80]: 100%|██████████████| 500/500 [00:27<00:00, 18.36it/s, loss=0.663]\n",
      "Epoch [14/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.62it/s, loss=0.712]\n",
      "Epoch [15/80]: 100%|██████████████| 500/500 [00:27<00:00, 18.50it/s, loss=0.647]\n",
      "Epoch [16/80]: 100%|██████████████| 500/500 [00:27<00:00, 18.34it/s, loss=0.493]\n",
      "Epoch [17/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.76it/s, loss=0.572]\n",
      "Epoch [18/80]: 100%|██████████████| 500/500 [00:27<00:00, 18.45it/s, loss=0.575]\n",
      "Epoch [19/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.57it/s, loss=0.455]\n",
      "Epoch [20/80]: 100%|██████████████| 500/500 [00:28<00:00, 17.24it/s, loss=0.449]\n",
      "Epoch [21/80]: 100%|██████████████| 500/500 [00:29<00:00, 17.10it/s, loss=0.437]\n",
      "Epoch [22/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.63it/s, loss=0.385]\n",
      "Epoch [23/80]: 100%|██████████████| 500/500 [00:28<00:00, 17.49it/s, loss=0.438]\n",
      "Epoch [24/80]: 100%|██████████████| 500/500 [00:29<00:00, 16.96it/s, loss=0.362]\n",
      "Epoch [25/80]: 100%|██████████████| 500/500 [00:29<00:00, 16.98it/s, loss=0.437]\n",
      "Epoch [26/80]: 100%|███████████████| 500/500 [00:27<00:00, 18.30it/s, loss=0.33]\n",
      "Epoch [27/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.63it/s, loss=0.253]\n",
      "Epoch [28/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.56it/s, loss=0.245]\n",
      "Epoch [29/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.61it/s, loss=0.192]\n",
      "Epoch [30/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.73it/s, loss=0.251]\n",
      "Epoch [31/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.71it/s, loss=0.327]\n",
      "Epoch [32/80]: 100%|███████████████| 500/500 [00:26<00:00, 18.73it/s, loss=0.23]\n",
      "Epoch [33/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.81it/s, loss=0.184]\n",
      "Epoch [34/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.74it/s, loss=0.165]\n",
      "Epoch [35/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.60it/s, loss=0.347]\n",
      "Epoch [36/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.75it/s, loss=0.291]\n",
      "Epoch [37/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.59it/s, loss=0.165]\n",
      "Epoch [38/80]: 100%|███████████████| 500/500 [00:27<00:00, 18.35it/s, loss=0.22]\n",
      "Epoch [39/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.72it/s, loss=0.218]\n",
      "Epoch [40/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.76it/s, loss=0.251]\n",
      "Epoch [41/80]: 100%|███████████████| 500/500 [00:26<00:00, 18.52it/s, loss=0.12]\n",
      "Epoch [42/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.65it/s, loss=0.185]\n",
      "Epoch [43/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.66it/s, loss=0.114]\n",
      "Epoch [44/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.65it/s, loss=0.193]\n",
      "Epoch [45/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.62it/s, loss=0.127]\n",
      "Epoch [46/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.85it/s, loss=0.161]\n",
      "Epoch [47/80]: 100%|█████████████| 500/500 [00:26<00:00, 18.73it/s, loss=0.0681]\n",
      "Epoch [48/80]: 100%|█████████████| 500/500 [00:26<00:00, 18.62it/s, loss=0.0873]\n",
      "Epoch [49/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.64it/s, loss=0.107]\n",
      "Epoch [50/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.81it/s, loss=0.095]\n",
      "Epoch [51/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.63it/s, loss=0.157]\n",
      "Epoch [52/80]: 100%|█████████████| 500/500 [00:26<00:00, 18.74it/s, loss=0.0606]\n",
      "Epoch [53/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.57it/s, loss=0.101]\n",
      "Epoch [54/80]: 100%|██████████████| 500/500 [00:26<00:00, 18.52it/s, loss=0.123]\n",
      "Epoch [55/80]: 100%|█████████████| 500/500 [00:27<00:00, 18.25it/s, loss=0.0781]\n",
      "Epoch [56/80]: 100%|█████████████| 500/500 [00:29<00:00, 16.94it/s, loss=0.0758]\n",
      "Epoch [57/80]: 100%|█████████████| 500/500 [00:29<00:00, 16.99it/s, loss=0.0546]\n",
      "Epoch [58/80]: 100%|█████████████| 500/500 [00:31<00:00, 15.68it/s, loss=0.0839]\n",
      "Epoch [59/80]: 100%|█████████████| 500/500 [00:32<00:00, 15.21it/s, loss=0.0566]\n",
      "Epoch [60/80]: 100%|██████████████| 500/500 [00:31<00:00, 15.86it/s, loss=0.113]\n",
      "Epoch [61/80]: 100%|█████████████| 500/500 [00:28<00:00, 17.66it/s, loss=0.0377]\n",
      "Epoch [62/80]: 100%|█████████████| 500/500 [00:27<00:00, 18.13it/s, loss=0.0416]\n",
      "Epoch [63/80]: 100%|█████████████| 500/500 [00:27<00:00, 18.05it/s, loss=0.0568]\n",
      "Epoch [64/80]: 100%|█████████████| 500/500 [00:27<00:00, 17.94it/s, loss=0.0695]\n",
      "Epoch [65/80]: 100%|█████████████| 500/500 [00:27<00:00, 18.16it/s, loss=0.0777]\n",
      "Epoch [66/80]: 100%|█████████████| 500/500 [00:27<00:00, 18.06it/s, loss=0.0674]\n",
      "Epoch [67/80]: 100%|███████████████| 500/500 [00:27<00:00, 17.99it/s, loss=0.12]\n",
      "Epoch [68/80]: 100%|█████████████| 500/500 [00:27<00:00, 17.91it/s, loss=0.0617]\n",
      "Epoch [69/80]: 100%|█████████████| 500/500 [00:28<00:00, 17.73it/s, loss=0.0661]\n",
      "Epoch [70/80]: 100%|██████████████| 500/500 [00:28<00:00, 17.74it/s, loss=0.062]\n",
      "Epoch [71/80]: 100%|█████████████| 500/500 [00:28<00:00, 17.72it/s, loss=0.0712]\n",
      "Epoch [72/80]: 100%|█████████████| 500/500 [00:28<00:00, 17.38it/s, loss=0.0682]\n",
      "Epoch [73/80]: 100%|█████████████| 500/500 [00:29<00:00, 17.12it/s, loss=0.0713]\n",
      "Epoch [74/80]: 100%|█████████████| 500/500 [00:31<00:00, 15.71it/s, loss=0.0411]\n",
      "Epoch [75/80]: 100%|█████████████| 500/500 [00:30<00:00, 16.15it/s, loss=0.0852]\n",
      "Epoch [76/80]: 100%|█████████████| 500/500 [00:30<00:00, 16.34it/s, loss=0.0882]\n",
      "Epoch [77/80]: 100%|██████████████| 500/500 [00:29<00:00, 17.09it/s, loss=0.047]\n",
      "Epoch [78/80]: 100%|██████████████| 500/500 [00:27<00:00, 17.95it/s, loss=0.022]\n",
      "Epoch [79/80]: 100%|█████████████| 500/500 [00:27<00:00, 17.97it/s, loss=0.0304]\n",
      "Epoch [80/80]: 100%|█████████████| 500/500 [00:26<00:00, 18.68it/s, loss=0.0538]\n",
      "Accuracy of the model on the test images: 85.29 %\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 1 train_resnet.py -c ./ckpt-torch_ddp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f99fd4-0268-41a9-b0cc-0bf4453c8594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
      "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
      "/root/miniconda3/lib/python3.8/site-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
      "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
      "\u001b[2;36m[04/11/24 14:36:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO:                    \n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/root/miniconda3/lib/python3.8/site-packages/coloss\u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35malai/\u001b[0m\u001b[95minitialize.py\u001b[0m:\u001b[1;36m67\u001b[0m launch                       \n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO: Distributed        \n",
      "\u001b[2;36m                    \u001b[0m         environment is initialized, world size: \u001b[1;36m1\u001b[0m          \n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
      "[extension] Time taken to compile cpu_adam_x86 op: 0.5408380031585693 seconds\n",
      "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
      "[extension] Time taken to compile fused_optim_cuda op: 0.6778891086578369 seconds\n",
      "Epoch [1/80]: 100%|████████████████| 500/500 [00:42<00:00, 11.74it/s, loss=1.43]\n",
      "Epoch [2/80]: 100%|████████████████| 500/500 [00:42<00:00, 11.65it/s, loss=1.15]\n",
      "Epoch [3/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.76it/s, loss=0.945]\n",
      "Epoch [4/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.84it/s, loss=0.977]\n",
      "Epoch [5/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.79it/s, loss=0.951]\n",
      "Epoch [6/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.65it/s, loss=0.844]\n",
      "Epoch [7/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.63it/s, loss=0.879]\n",
      "Epoch [8/80]: 100%|████████████████| 500/500 [00:43<00:00, 11.62it/s, loss=0.75]\n",
      "Epoch [9/80]: 100%|███████████████| 500/500 [00:43<00:00, 11.55it/s, loss=0.802]\n",
      "Epoch [10/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.51it/s, loss=0.804]\n",
      "Epoch [11/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.71it/s, loss=0.731]\n",
      "Epoch [12/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.59it/s, loss=0.696]\n",
      "Epoch [13/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.67it/s, loss=0.702]\n",
      "Epoch [14/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.55it/s, loss=0.647]\n",
      "Epoch [15/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.50it/s, loss=0.537]\n",
      "Epoch [16/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.68it/s, loss=0.538]\n",
      "Epoch [17/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.68it/s, loss=0.634]\n",
      "Epoch [18/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.68it/s, loss=0.593]\n",
      "Epoch [19/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.76it/s, loss=0.492]\n",
      "Epoch [20/80]: 100%|██████████████| 500/500 [00:40<00:00, 12.46it/s, loss=0.432]\n",
      "Epoch [21/80]: 100%|██████████████| 500/500 [00:41<00:00, 12.11it/s, loss=0.328]\n",
      "Epoch [22/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.63it/s, loss=0.391]\n",
      "Epoch [23/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.73it/s, loss=0.435]\n",
      "Epoch [24/80]: 100%|███████████████| 500/500 [00:42<00:00, 11.89it/s, loss=0.48]\n",
      "Epoch [25/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.46it/s, loss=0.407]\n",
      "Epoch [26/80]: 100%|██████████████| 500/500 [00:46<00:00, 10.79it/s, loss=0.291]\n",
      "Epoch [27/80]: 100%|██████████████| 500/500 [00:45<00:00, 11.01it/s, loss=0.319]\n",
      "Epoch [28/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.44it/s, loss=0.368]\n",
      "Epoch [29/80]: 100%|██████████████| 500/500 [00:45<00:00, 11.04it/s, loss=0.203]\n",
      "Epoch [30/80]: 100%|██████████████| 500/500 [00:44<00:00, 11.16it/s, loss=0.298]\n",
      "Epoch [31/80]: 100%|██████████████| 500/500 [00:44<00:00, 11.22it/s, loss=0.302]\n",
      "Epoch [32/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.40it/s, loss=0.255]\n",
      "Epoch [33/80]: 100%|██████████████| 500/500 [00:43<00:00, 11.54it/s, loss=0.313]\n",
      "Epoch [34/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.63it/s, loss=0.233]\n",
      "Epoch [35/80]: 100%|██████████████| 500/500 [00:45<00:00, 11.11it/s, loss=0.237]\n",
      "Epoch [36/80]: 100%|██████████████| 500/500 [00:46<00:00, 10.81it/s, loss=0.389]\n",
      "Epoch [37/80]: 100%|███████████████| 500/500 [00:40<00:00, 12.22it/s, loss=0.25]\n",
      "Epoch [38/80]: 100%|██████████████| 500/500 [00:46<00:00, 10.86it/s, loss=0.254]\n",
      "Epoch [39/80]: 100%|██████████████| 500/500 [00:47<00:00, 10.51it/s, loss=0.234]\n",
      "Epoch [40/80]: 100%|██████████████| 500/500 [00:47<00:00, 10.54it/s, loss=0.142]\n",
      "Epoch [41/80]: 100%|█████████████| 500/500 [00:45<00:00, 10.90it/s, loss=0.0999]\n",
      "Epoch [42/80]: 100%|██████████████| 500/500 [00:47<00:00, 10.60it/s, loss=0.176]\n",
      "Epoch [43/80]: 100%|██████████████| 500/500 [00:45<00:00, 11.10it/s, loss=0.107]\n",
      "Epoch [44/80]: 100%|██████████████| 500/500 [00:48<00:00, 10.29it/s, loss=0.131]\n",
      "Epoch [45/80]: 100%|█████████████| 500/500 [00:46<00:00, 10.77it/s, loss=0.0869]\n",
      "Epoch [46/80]: 100%|██████████████| 500/500 [00:47<00:00, 10.48it/s, loss=0.122]\n",
      "Epoch [47/80]: 100%|█████████████| 500/500 [00:47<00:00, 10.61it/s, loss=0.0892]\n",
      "Epoch [48/80]: 100%|█████████████| 500/500 [00:45<00:00, 11.09it/s, loss=0.0804]\n",
      "Epoch [49/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.10it/s, loss=0.0819]\n",
      "Epoch [50/80]: 100%|██████████████| 500/500 [00:41<00:00, 11.96it/s, loss=0.118]\n",
      "Epoch [51/80]: 100%|█████████████| 500/500 [00:42<00:00, 11.68it/s, loss=0.0388]\n",
      "Epoch [52/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.02it/s, loss=0.0584]\n",
      "Epoch [53/80]: 100%|█████████████| 500/500 [00:42<00:00, 11.88it/s, loss=0.0784]\n",
      "Epoch [54/80]: 100%|██████████████| 500/500 [00:41<00:00, 11.94it/s, loss=0.143]\n",
      "Epoch [55/80]: 100%|█████████████| 500/500 [00:41<00:00, 11.97it/s, loss=0.0528]\n",
      "Epoch [56/80]: 100%|██████████████| 500/500 [00:41<00:00, 11.94it/s, loss=0.108]\n",
      "Epoch [57/80]: 100%|█████████████| 500/500 [00:42<00:00, 11.88it/s, loss=0.0799]\n",
      "Epoch [58/80]: 100%|█████████████| 500/500 [00:42<00:00, 11.90it/s, loss=0.0774]\n",
      "Epoch [59/80]: 100%|██████████████| 500/500 [00:41<00:00, 12.06it/s, loss=0.117]\n",
      "Epoch [60/80]: 100%|██████████████| 500/500 [00:41<00:00, 11.98it/s, loss=0.106]\n",
      "Epoch [61/80]: 100%|█████████████| 500/500 [00:40<00:00, 12.37it/s, loss=0.0719]\n",
      "Epoch [62/80]: 100%|█████████████| 500/500 [00:42<00:00, 11.78it/s, loss=0.0949]\n",
      "Epoch [63/80]: 100%|█████████████| 500/500 [00:41<00:00, 11.96it/s, loss=0.0892]\n",
      "Epoch [64/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.11it/s, loss=0.0657]\n",
      "Epoch [65/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.05it/s, loss=0.0887]\n",
      "Epoch [66/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.15it/s, loss=0.0533]\n",
      "Epoch [67/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.14it/s, loss=0.0394]\n",
      "Epoch [68/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.05it/s, loss=0.0649]\n",
      "Epoch [69/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.03it/s, loss=0.0859]\n",
      "Epoch [70/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.18it/s, loss=0.0729]\n",
      "Epoch [71/80]: 100%|██████████████| 500/500 [00:41<00:00, 12.08it/s, loss=0.105]\n",
      "Epoch [72/80]: 100%|█████████████| 500/500 [00:43<00:00, 11.62it/s, loss=0.0634]\n",
      "Epoch [73/80]: 100%|█████████████| 500/500 [00:46<00:00, 10.72it/s, loss=0.0547]\n",
      "Epoch [74/80]: 100%|█████████████| 500/500 [00:46<00:00, 10.72it/s, loss=0.0409]\n",
      "Epoch [75/80]: 100%|██████████████| 500/500 [00:46<00:00, 10.83it/s, loss=0.109]\n",
      "Epoch [76/80]: 100%|██████████████| 500/500 [00:42<00:00, 11.76it/s, loss=0.064]\n",
      "Epoch [77/80]: 100%|█████████████| 500/500 [00:41<00:00, 12.06it/s, loss=0.0527]\n",
      "Epoch [78/80]: 100%|█████████████| 500/500 [00:41<00:00, 11.99it/s, loss=0.0215]\n",
      "Epoch [79/80]:  48%|██████▊       | 242/500 [00:20<00:21, 12.19it/s, loss=0.141]"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node 1 train_resnet.py -c ./ckpt_resnet-low_level_zero -p low_level_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b46553-d6cc-4b2b-8801-8430c0c6dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
